/**
 * IBKR News Ingestion Pipeline
 *
 * Fetches news headlines from IBKR for all active tickers,
 * classifies them with Anthropic AI, and stores in the database.
 *
 * Steps:
 * 1. Connect to IBKR, get available providers
 * 2. Load active tickers from DB, resolve conIds
 * 3. Fetch headlines for each ticker (last 24h by default)
 * 4. Deduplicate against existing news_events
 * 5. Parse IBKR metadata (sentiment/confidence from headline tags)
 * 6. Classify with Anthropic API (event_type, severity, summary, sector)
 * 7. Insert into news_events, news_ticker_map, news_sector_map
 *
 * Run: pnpm run news:fetch
 * Options: --days=7 --tickers=EQNR,DNB --dry-run --skip-ai
 */

import { TWSClient, SecType, type NewsHeadline } from "@ineqre/ibkr";
import { Pool } from "pg";
import Anthropic from "@anthropic-ai/sdk";
import * as dotenv from "dotenv";
import * as path from "path";

dotenv.config({ path: path.resolve(__dirname, "../../../.env") });
dotenv.config({ path: path.resolve(__dirname, "../.env.local") });

// ── Config ──
const DAYS_BACK = parseInt(process.argv.find(a => a.startsWith("--days="))?.split("=")[1] ?? "1");
const TICKER_FILTER = process.argv.find(a => a.startsWith("--tickers="))?.split("=")[1]?.split(",");
const DRY_RUN = process.argv.includes("--dry-run");
const SKIP_AI = process.argv.includes("--skip-ai");
const PROVIDER_CODES = "BRFG+BRFUPDN+DJNL+DJ-N+DJ-RT+DJ-RTE+DJ-RTG+FLY";
const DELAY_MS = 500;     // Between ticker requests

// ── DB setup ──
const dbUrl = (process.env.DATABASE_URL || "").trim().replace(/^["']|["']$/g, "");
// Force disable TLS cert verification for Supabase pooler
process.env.NODE_TLS_REJECT_UNAUTHORIZED = "0";
const pool = new Pool({ connectionString: dbUrl });

// ── Anthropic setup ──
const anthropic = process.env.ANTHROPIC_API_KEY
  ? new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })
  : null;

// ── Helpers ──
function formatDate(d: Date): string {
  return d.toISOString().replace("T", " ").slice(0, 19);
}

/**
 * Detect auto-generated market commentary with zero analytical value.
 * e.g. "Equinor ASA Stock Falls Friday, Underperforms Market"
 */
function isAutoGeneratedJunk(headline: string): boolean {
  const h = headline.toLowerCase();
  return (
    (/stock (falls|rises|drops|gains|slips|climbs|tumbles|surges|advances|declines)/i.test(headline) &&
     /((under|out)performs market|market (gains|losses))/i.test(headline)) ||
    /mid-morning market update/i.test(headline) ||
    /mid-day market update/i.test(headline) ||
    /market wrap/i.test(headline) ||
    h.includes("top stock market stories") ||
    h.includes("what's worth watching") ||
    // Low-value corporate housekeeping
    h.includes("invitation to") ||
    h.includes("financial calendar") ||
    h.includes("notice of extraordinary general meeting") ||
    h.includes("notice of annual general meeting") ||
    h.includes("notice of general meeting") ||
    /key information relating to .* dividend/i.test(headline)
  );
}

interface ParsedMeta {
  headline: string;        // Clean headline (tags stripped)
  ibkrSentiment: number | null;
  ibkrConfidence: number | null;
  language: string | null;
}

/**
 * Parse IBKR headline metadata tags:
 * {A:800015:L:en:K:-0.97:C:0.97}Actual headline text
 */
function parseHeadlineMeta(raw: string): ParsedMeta {
  const match = raw.match(/^\{([^}]+)\}(.*)$/);
  if (!match) return { headline: raw, ibkrSentiment: null, ibkrConfidence: null, language: null };

  const tagStr = match[1];
  const headline = match[2].trim();
  let ibkrSentiment: number | null = null;
  let ibkrConfidence: number | null = null;
  let language: string | null = null;

  // Parse K: (sentiment) and C: (confidence) and L: (language)
  const kMatch = tagStr.match(/K:(-?[\d.]+)/);
  const cMatch = tagStr.match(/C:([\d.]+)/);
  const lMatch = tagStr.match(/L:(\w+)/);

  if (kMatch) ibkrSentiment = parseFloat(kMatch[1]);
  if (cMatch) ibkrConfidence = parseFloat(cMatch[1]);
  if (lMatch) language = lMatch[1];

  return { headline, ibkrSentiment, ibkrConfidence, language };
}

interface ClassifiedHeadline {
  eventType: string;
  severity: number;
  sentiment: number;
  confidence: number;
  summary: string;
  structuredFacts: Record<string, string | number | null>;
  affectedTickers: { ticker: string; relevance: number; direction: string }[];
  sectors: { sector: string; impact: number }[];
}

/**
 * Strip HTML tags and clean article text from IBKR
 */
function cleanArticleText(raw: string): string {
  return raw
    .replace(/<[^>]+>/g, " ")
    .replace(/&#10;/g, "\n")
    .replace(/&#13;/g, "")
    .replace(/&nbsp;/g, " ")
    .replace(/&amp;/g, "&")
    .replace(/&lt;/g, "<")
    .replace(/&gt;/g, ">")
    .replace(/&quot;/g, '"')
    .replace(/&#39;/g, "'")
    .replace(/&apos;/g, "'")
    .replace(/&#\d+;/g, "")
    .replace(/[ \t]+/g, " ")
    .replace(/\n\s*\n/g, "\n")
    .trim();
}

/**
 * Classify articles with Anthropic API (with retry on rate limit)
 */
async function classifyArticle(
  headline: string,
  articleText: string,
  ibkrSentiment: number | null,
  tickerList: string[],
  retries = 3
): Promise<ClassifiedHeadline> {
  if (!anthropic) {
    return {
      eventType: "other",
      severity: 2,
      sentiment: ibkrSentiment ?? 0,
      confidence: 0.5,
      summary: headline.slice(0, 200),
      structuredFacts: {},
      affectedTickers: [],
      sectors: [],
    };
  }

  const bodyText = articleText.length > 4000 ? articleText.slice(0, 4000) + "..." : articleText;
  const hasArticle = bodyText.length > 20;

  const prompt = `You are a financial news analyst for Oslo Stock Exchange (OSE).

Given this news article, extract ALL key facts and classify it. Return ONLY valid JSON.

Available OSE tickers: ${tickerList.slice(0, 50).join(", ")}

HEADLINE: ${headline}
${hasArticle ? `\nFULL ARTICLE TEXT:\n${bodyText}` : ""}

Return this exact JSON structure:
{
  "event_type": "earnings"|"guidance"|"insider_trade"|"regulatory"|"macro"|"geopolitical"|"analyst_action"|"corporate_action"|"sector_news"|"other",
  "severity": <1-5>,
  "sentiment": <-1.0 to 1.0>,
  "confidence": <0.0 to 1.0>,
  "summary": "<2-3 sentences capturing KEY FACTS — amounts, names, numbers>",
  "structured_facts": {
    "transaction_type": "BUY"|"SELL"|null,
    "person_name": "<insider name>" or null,
    "person_role": "<CEO, Board, etc>" or null,
    "shares_traded": <number> or null,
    "price_per_share": <number in NOK> or null,
    "total_value_nok": <number> or null,
    "holdings_after": <number> or null,
    "action_type": "buyback"|"dividend"|"split"|"merger"|null,
    "shares_count": <number> or null,
    "program_total": "<size>" or null,
    "dividend_per_share": <number> or null,
    "ex_date": "<YYYY-MM-DD>" or null,
    "revenue": "<amount>" or null,
    "eps": <number> or null,
    "beat_miss": "beat"|"miss"|"inline"|null,
    "broker": "<broker name>" or null,
    "rating": "<buy/sell/hold>" or null,
    "target_price": <number> or null,
    "key_quote": "<important direct quote>" or null
  },
  "tickers": [{"ticker": "XXX", "relevance": 0.0-1.0, "direction": "positive"|"negative"|"neutral"}],
  "sectors": [{"sector": "<sector>", "impact": -1.0 to 1.0}]
}

RULES:
- Extract EVERY number (NOK amounts, share counts, percentages)
- For insider trades: always extract person name, role, shares, value
- For buybacks: extract shares and total value
- If article is auto-generated market commentary with no real facts, set severity=1
- Map companies to OSE tickers from the list
- Summary MUST include key numbers, not generic descriptions
- Return ONLY JSON, no markdown`;

  for (let attempt = 0; attempt < retries; attempt++) {
    try {
      const message = await anthropic.messages.create({
        model: "claude-haiku-4-5-20251001",
        max_tokens: 2000,
        messages: [{ role: "user", content: prompt }],
      });

      const text = (message.content[0] as { text: string }).text || "";
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) throw new Error("No JSON in response");

      const r = JSON.parse(jsonMatch[0]);
      return {
        eventType: r.event_type || "other",
        severity: Math.max(1, Math.min(5, r.severity || 2)),
        sentiment: Math.max(-1, Math.min(1, r.sentiment ?? ibkrSentiment ?? 0)),
        confidence: Math.max(0, Math.min(1, r.confidence ?? 0.5)),
        summary: r.summary || headline.slice(0, 200),
        structuredFacts: r.structured_facts || {},
        affectedTickers: (r.tickers || []).filter((t: any) => tickerList.includes(t.ticker)),
        sectors: r.sectors || [],
      };
    } catch (err: any) {
      const isRateLimit = err?.status === 429 || err?.message?.includes("429");
      if (isRateLimit && attempt < retries - 1) {
        const wait = (attempt + 1) * 10_000; // 10s, 20s, 30s
        console.error(`  ⚠ Rate limited, waiting ${wait / 1000}s...`);
        await new Promise(r => setTimeout(r, wait));
        continue;
      }
    }
  }

  // All retries failed — fallback
  console.error(`  ⚠ AI classification failed after ${retries} attempts`);
  return {
    eventType: "other",
    severity: 2,
    sentiment: ibkrSentiment ?? 0,
    confidence: 0.5,
    summary: headline.slice(0, 200),
    structuredFacts: {},
    affectedTickers: [],
    sectors: [],
  };
}

// ── Main Pipeline ──
async function main() {
  console.log(`=== IBKR News Ingestion Pipeline ===`);
  console.log(`Days back: ${DAYS_BACK} | Tickers: ${TICKER_FILTER?.join(",") || "all"} | Dry run: ${DRY_RUN} | Skip AI: ${SKIP_AI}\n`);

  const client = new TWSClient();

  try {
    // 1. Connect
    console.log("Connecting to IB Gateway...");
    await client.connect();
    console.log("✓ Connected\n");

    // 2. Load tickers from DB
    let tickerQuery = `SELECT ticker, name, sector FROM stocks WHERE is_active = true`;
    const params: string[] = [];
    if (TICKER_FILTER) {
      tickerQuery += ` AND ticker = ANY($1)`;
      params.push(TICKER_FILTER as any);
    }
    tickerQuery += ` ORDER BY ticker`;

    const { rows: tickers } = await pool.query(tickerQuery, params.length ? [TICKER_FILTER] : []);
    const tickerList = tickers.map((t: any) => t.ticker);
    const sectorMap = new Map(tickers.map((t: any) => [t.ticker, t.sector]));
    console.log(`Loaded ${tickers.length} tickers from DB\n`);

    // 3. Date range
    const now = new Date();
    const start = new Date(now.getTime() - DAYS_BACK * 24 * 60 * 60 * 1000);
    const startDt = formatDate(start);
    const endDt = formatDate(now);
    console.log(`Fetching news from ${startDt} to ${endDt}\n`);

    // 4. Load existing article_ids for dedup
    const { rows: existing } = await pool.query(
      `SELECT article_id FROM news_events WHERE article_id IS NOT NULL AND published_at >= $1`,
      [start.toISOString()]
    );
    const existingIds = new Set(existing.map((r: any) => r.article_id));
    console.log(`${existingIds.size} existing articles in DB for dedup\n`);

    // 5. Fetch headlines for each ticker
    type RawHeadline = NewsHeadline & ParsedMeta & { sourceTicker: string; articleText: string };
    const allHeadlines: RawHeadline[] = [];
    const seenArticleIds = new Set<string>();
    let resolved = 0, failed = 0;

    for (const ticker of tickerList) {
      try {
        // Resolve conId
        const exchange = ticker.endsWith(".US") ? "SMART" : "OSE";
        const currency = ticker.endsWith(".US") ? "USD" : "NOK";
        const symbol = ticker.replace(".US", "");

        const conId = await client.resolveContractId(symbol, exchange, SecType.STK, currency);

        // Fetch headlines
        const headlines = await client.getHistoricalNews(conId, PROVIDER_CODES, startDt, endDt, 50);

        let newCount = 0;
        for (const h of headlines) {
          // Dedup: skip if already in DB or already seen in this run
          if (existingIds.has(h.articleId) || seenArticleIds.has(h.articleId)) continue;
          seenArticleIds.add(h.articleId);

          const parsed = parseHeadlineMeta(h.headline);
          // Skip non-English content
          if (parsed.language && parsed.language !== "en") continue;
          // Skip auto-generated market commentary
          if (isAutoGeneratedJunk(parsed.headline)) continue;

          // Fetch full article text
          let articleText = "";
          try {
            const article = await client.getNewsArticle(h.providerCode, h.articleId);
            articleText = cleanArticleText(article.articleText);
          } catch {
            // Article fetch may timeout — proceed with headline only
          }

          allHeadlines.push({
            ...h,
            ...parsed,
            sourceTicker: ticker,
            articleText,
          });
          newCount++;

          // Rate limit between article fetches
          await new Promise(r => setTimeout(r, 300));
        }

        resolved++;
        if (newCount > 0) {
          console.log(`  ${ticker}: ${headlines.length} total, ${newCount} new (${allHeadlines.filter(h => h.sourceTicker === ticker && h.articleText.length > 10).length} with articles)`);
        }
      } catch (err) {
        failed++;
        // Silently skip tickers that fail (e.g., no IBKR contract)
      }

      // Rate limit
      await new Promise(r => setTimeout(r, DELAY_MS));
    }

    console.log(`\nResolved: ${resolved}/${tickerList.length} tickers, Failed: ${failed}`);
    console.log(`New headlines to process: ${allHeadlines.length}\n`);

    if (allHeadlines.length === 0) {
      console.log("No new headlines. Done.");
      return;
    }

    if (DRY_RUN) {
      console.log("=== DRY RUN — would insert these headlines ===");
      for (const h of allHeadlines.slice(0, 20)) {
        console.log(`  [${h.time}] (${h.providerCode}) ${h.headline}`);
        console.log(`    IBKR sentiment: ${h.ibkrSentiment}, confidence: ${h.ibkrConfidence}`);
      }
      if (allHeadlines.length > 20) console.log(`  ... and ${allHeadlines.length - 20} more`);
      return;
    }

    // 6. Classify with AI (parallel batches for speed)
    const AI_CONCURRENCY = 3;
    console.log(`Classifying articles with AI (concurrency=${AI_CONCURRENCY})...`);
    const classified: ClassifiedHeadline[] = new Array(allHeadlines.length);

    for (let i = 0; i < allHeadlines.length; i += AI_CONCURRENCY) {
      const batch = allHeadlines.slice(i, i + AI_CONCURRENCY);
      const results = await Promise.all(
        batch.map((h, j) => {
          if (SKIP_AI) {
            return Promise.resolve<ClassifiedHeadline>({
              eventType: "other",
              severity: 2,
              sentiment: h.ibkrSentiment ?? 0,
              confidence: 0.5,
              summary: h.headline.slice(0, 200),
              structuredFacts: {},
              affectedTickers: [],
              sectors: [],
            });
          }
          return classifyArticle(h.headline, h.articleText, h.ibkrSentiment, tickerList);
        })
      );
      for (let j = 0; j < results.length; j++) {
        classified[i + j] = results[j];
      }
      const done = Math.min(i + AI_CONCURRENCY, allHeadlines.length);
      if (done % 50 === 0 || done === allHeadlines.length) {
        console.log(`  Classified ${done}/${allHeadlines.length}`);
      }
    }

    // 7. Insert into DB
    console.log("\nInserting into database...");
    let insertedEvents = 0, insertedTickers = 0, insertedSectors = 0;

    let skippedLowValue = 0;
    for (let i = 0; i < allHeadlines.length; i++) {
      const h = allHeadlines[i];
      const c = classified[i];

      // Skip low-value articles (severity 1 = no analytical value)
      if (c.severity <= 1) {
        skippedLowValue++;
        continue;
      }

      try {
        // Insert news_event (with raw_content and structured_facts)
        const { rows } = await pool.query(
          `INSERT INTO news_events (
            published_at, source, headline, summary, article_id,
            event_type, severity, sentiment, confidence,
            provider_code, ibkr_sentiment, ibkr_confidence,
            raw_content, structured_facts
          ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
          ON CONFLICT (article_id, source) DO NOTHING
          RETURNING id`,
          [
            h.time,
            `ibkr_${h.providerCode.toLowerCase()}`,
            h.headline,
            c.summary,
            h.articleId,
            c.eventType,
            c.severity,
            c.sentiment,
            c.confidence,
            h.providerCode,
            h.ibkrSentiment,
            h.ibkrConfidence,
            h.articleText.length > 10 ? h.articleText : null,
            Object.keys(c.structuredFacts).length > 0 ? JSON.stringify(c.structuredFacts) : null,
          ]
        );

        if (rows.length === 0) continue; // Duplicate
        const eventId = rows[0].id;
        insertedEvents++;

        // Always link to the source ticker
        const tickersToLink = new Map<string, { relevance: number; direction: string }>();
        tickersToLink.set(h.sourceTicker, {
          relevance: 1.0,
          direction: c.sentiment > 0.2 ? "positive" : c.sentiment < -0.2 ? "negative" : "neutral",
        });

        // Add AI-identified tickers
        for (const t of c.affectedTickers) {
          if (!tickersToLink.has(t.ticker)) {
            tickersToLink.set(t.ticker, { relevance: t.relevance, direction: t.direction });
          }
        }

        // Insert ticker mappings
        for (const [ticker, info] of tickersToLink) {
          try {
            await pool.query(
              `INSERT INTO news_ticker_map (news_event_id, ticker, relevance_score, impact_direction)
               VALUES ($1, $2, $3, $4) ON CONFLICT DO NOTHING`,
              [eventId, ticker, info.relevance, info.direction]
            );
            insertedTickers++;
          } catch { /* FK constraint — ticker not in stocks table */ }
        }

        // Insert sector mappings
        for (const s of c.sectors) {
          try {
            await pool.query(
              `INSERT INTO news_sector_map (news_event_id, sector, impact_score)
               VALUES ($1, $2, $3) ON CONFLICT DO NOTHING`,
              [eventId, s.sector, s.impact]
            );
            insertedSectors++;
          } catch { /* ignore */ }
        }

        // Also add sector from the source ticker
        const tickerSector = sectorMap.get(h.sourceTicker);
        if (tickerSector) {
          try {
            await pool.query(
              `INSERT INTO news_sector_map (news_event_id, sector, impact_score)
               VALUES ($1, $2, $3) ON CONFLICT DO NOTHING`,
              [eventId, tickerSector, c.sentiment]
            );
            insertedSectors++;
          } catch { /* ignore */ }
        }
      } catch (err) {
        console.error(`  ✗ Failed to insert headline: ${(err as Error).message}`);
      }
    }

    console.log(`\n=== Done ===`);
    console.log(`  Events:  ${insertedEvents} inserted (${skippedLowValue} low-value skipped)`);
    console.log(`  Tickers: ${insertedTickers} mappings`);
    console.log(`  Sectors: ${insertedSectors} mappings`);

  } catch (err) {
    console.error("Fatal error:", (err as Error).message);
    process.exit(1);
  } finally {
    await client.disconnect();
    await pool.end();
    console.log("Disconnected.");
    setTimeout(() => process.exit(0), 1000);
  }
}

main();
